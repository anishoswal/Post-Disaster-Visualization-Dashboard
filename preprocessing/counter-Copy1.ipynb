{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    return re.sub(r'[^a-zA-Z ]', \"\", text).lower().lstrip().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(np):\n",
    "    \n",
    "    stop_words = [line.rstrip('\\n') for line in open('stopwordList.txt')]\n",
    "    new_np = ''\n",
    "    words = list(np.split()) \n",
    "    words = [w for w in words if w.lower() not in stop_words]\n",
    "    word_to_add = ' '.join(words)\n",
    "    if len(word_to_add) > 1:\n",
    "        new_np = word_to_add\n",
    "    return new_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_np_sent_dicts = pkl.load(open('temp/ne_np_sent_all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ne_np': ['evening'], 'sentence': 'As always the evening was wonderful and inspiring to watch, and I am very excited to have a good one.'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ne_np_sent_dicts[100])\n",
    "print('11'.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dict_text(ne_np_sent_dicts):\n",
    "    \n",
    "    stop = [line.rstrip('\\n') for line in open('stop.txt')]\n",
    "#     txt = [{'ne_np': ['a  ad bubble exclusion zones', 'a  billion bailout', 'a  de la grande guerre patriotique', 'a  fillup', 'a  job', 'a  million antiterrorist center', 'a  trillion tax cut', 'a  year old asian woman', 'a a'], 'sentence': \"Someone had to draw my att\"}]\n",
    "    ne_np_sent_clean = []\n",
    "    for ne_np_sent in tqdm(ne_np_sent_dicts):\n",
    "        clean_ne_np = []\n",
    "        for ne in ne_np_sent['ne_np']:\n",
    "            ne = clean(ne)\n",
    "            ne = remove_stop_words(ne)\n",
    "    #     ne = ''\n",
    "    #     try:\n",
    "    #         ne = clean(item[0])\n",
    "    #         print(ne)\n",
    "    #     except:\n",
    "    #         pass\n",
    "            if ne != '' and len(ne) > 2 and ne.isnumeric() == False and ne.lower() not in stop:\n",
    "                clean_ne_np.append(ne)\n",
    "        if len(clean_ne_np) > 0:    \n",
    "            ne_np_sent_clean.append({'ne_np':clean_ne_np, 'sentence': ne_np_sent['sentence']})\n",
    "    return ne_np_sent_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 41941/41941 [00:49<00:00, 841.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ne_np_sent_clean = list_of_dict_text(ne_np_sent_dicts)\n",
    "pkl.dump(ne_np_sent_clean, open('temp/ne_np_sent_clean.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 38715/38715 [00:00<00:00, 289216.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38715\n",
      "{'ne_np': ['sales', 'theesehese', 'advantheeseage'], 'sentence': 'Take advantheeseage of theesehese One, theeserembling sales!'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "ne_np_sent_clean_final = []\n",
    "for item in tqdm(ne_np_sent_clean):\n",
    "    tmp = list(set(item['ne_np']))\n",
    "    ne_np_sent_clean_final.append({'ne_np': tmp, 'sentence': item['sentence']})\n",
    "\n",
    "print(len(ne_np_sent_clean_final))\n",
    "pkl.dump(ne_np_sent_clean_final, open('temp/ne_np_sent_clean_final.pkl', 'wb'))\n",
    "print(ne_np_sent_clean_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 38715/38715 [00:53<00:00, 719.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tmp = pkl.load(open('temp/ne_np_sent_clean_final.pkl', 'rb'))\n",
    "tmp = list_of_dict_text(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_vocab(input_list):\n",
    "    # input to this function is a list of dicts\n",
    "    #  sample of input:  [{'ne_np':['number', 'letters', 'daily mail', 'sentence': \"Someone had to draw my attention to these 2 letters published by the Daily Mail\"]},\n",
    "    #                     {'ne_np':['adc','dxc'], 'sentence': \"llgh sleihg sglh\"}]\n",
    "    features = []\n",
    "    vocab = []\n",
    "    for item in tqdm(input_list):\n",
    "        features.append(item['ne_np'])\n",
    "        vocab.extend(item['ne_np'])\n",
    "    # features is a list of list\n",
    "    # vocab is list of str,\n",
    "    return features, sorted(list(set(vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 38715/38715 [00:00<00:00, 2193557.48it/s]\n"
     ]
    }
   ],
   "source": [
    "features , vocab = get_features_vocab(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaaaaaa', 'aaaaaaaaagh', 'aaaaaaaahhhh', 'aaaaaarrrrrrrrr', 'aaaand', 'aaah', 'aabound', 'aah', 'aahs', 'aannndd', 'aannndd afteralll', 'aanythingonigone', 'aanythingonigone lord production', 'aaron', 'abandon bathroom', 'abanyone', 'abboutbout', 'abboutbout nucleabboutr power', 'abboutnd', 'ability', 'abis', 'ablout', 'abodes', 'aboion', 'abortion', 'abotu bottle', 'abotubout', 'abotubout gabotus abotund food', 'abotund', 'aboutcan', 'abouteh tehhe sewers untehil justeh', 'aboutheese', 'abouthge', 'aboutje', 'aboutje tjehe foliukeliukeowers', 'aboutwonder', 'abrupt politically expedient someneomeone', 'abs', 'absolute champ', 'absolute savage coyote roast', 'absolute terror', 'absolute trust', 'absolutehely loved iteh', 'absolutely', 'absolutely flavor', 'absolutely horrible reception', 'abstinence', 'abstract modern art section', 'absurd', 'abuse', 'academics', 'academy', 'academy training room', 'acaulco', 'acc', 'accenhtey', 'accent', 'accents', 'access', 'accessory', 'accidantccident', 'accidenhtis', 'accident', 'accidentihsomene', 'accidentje', 'accidentyhe', 'accinformtiondent', 'accintepretationdent', 'accommodations', 'accompanied software', 'account', 'accountant', 'accountanything arseuming', 'accounts', 'accross', 'accrossbout', 'accrosscross', 'accrossll', 'accrossll accrossreaccrosss', 'accrossreaccrosss', 'accuracy', 'accursedholy blade', 'ache', 'aches', 'achiever', 'achivement', 'acid', 'acne', 'acorss', 'acres', 'acronyms', 'act', 'acted scene', 'acthierors', 'acting', 'acting ability', 'actiolthern', 'action', 'actions', 'activatedwaste', 'active liekifestylieke', 'active lifestyle', 'activism', 'activist', 'activities', 'activity', 'actor', 'actors', 'actress', 'actresses', 'acts', 'actual birth', 'actual birthday', 'actual experience', 'actual fisures', 'actual player', 'actual relationship', 'actual spare', 'actuanyoney', 'actyhation', 'adam', 'adaptation', 'adapters', 'add', 'add betty white', 'added bonuses', 'adderall', 'addict', 'addiction', 'addionaldditionaddionall', 'addition', 'addoptpaddopt', 'addoptre', 'address', 'adequate safe shelter', 'adfree content', 'adjustjementje', 'admin', 'admin stuff', 'administoghetherratoghetherorsophie', 'administratorsophie', 'administratorsophie people', 'administratorsophie smaaart', 'administratorsophie sorry', 'administratorsophie sorryyy', 'administratorsophie ytouou', 'administratorsophiewaste', 'adminisufferringtratorsophie', 'admins', 'adminstration', 'adn', 'adn british', 'adn nucleadnr', 'adn nurse thadnt', 'adn trip', 'adnftershocks', 'adngadnin', 'adnheadnd', 'adnll', 'adnlone', 'adnlwadnys', 'adnn', 'adnn explosion adnt', 'adnnd', 'adnnd sadnfe pladnces adnt', 'adnnd stradnightforwadnrd', 'adnnd tgheender', 'adnnyone', 'adnnyone adnnd', 'adnnyone beadnutifully simple adnnd stradnightforwadnrd displadny', 'adnnything', 'adnre', 'adnreadn', 'adnreadn colladnpsed adnnd', 'adnrseistehyadnnce', 'adnrseistehyadnnce adngadnin', 'adns', 'adnt', 'adntmosphere', 'adonigministratorsophie', 'adonigministratorsophie slammedonig', 'adorbs', 'adrenaline', 'adresnd', 'adresre', 'adresre relevadresnt', 'adrian', 'ads', 'adult', 'adult hygiene kits', 'adultery', 'adults', 'advanage', 'advance', 'advanced machine learning techniques', 'advanced malaria vaccine', 'advancement', 'advanhtisage', 'advantage', 'advantages']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16853\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for i in range(len(features)):\n",
    "    vocab.extend(features[i])\n",
    "vocab = sorted(list(set(vocab)))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 41941/41941 [00:00<00:00, 1105976.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for ne_np_sent_dict in tqdm(ne_np_sent_dicts):\n",
    "    for ne_np in ne_np_sent_dict['ne_np']:\n",
    "        counter[ne_np] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['theesehese', 'advantheeseage', 'sales', 'someneomeone', 'behinderte', 'mieten', 'und behinderte', 'month', 'vibedorerating opportunity', 'opportunity']\n"
     ]
    }
   ],
   "source": [
    "len(counter)\n",
    "\n",
    "print(list(counter.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 41941/41941 [00:00<00:00, 982673.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for ne_np_sent_dict in tqdm(ne_np_sent_dicts):\n",
    "    for ne_np in ne_np_sent_dict['ne_np']:\n",
    "        counter[ne_np] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Daily Mail'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f4fc4eb33d02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Daily Mail'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'Daily Mail'"
     ]
    }
   ],
   "source": [
    "print(counter['Daily Mail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17123/17123 [00:00<00:00, 1574668.76it/s]\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for key, value in tqdm(counter.items()):\n",
    "    final.append([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_np_df = pd.DataFrame(final, columns = ['ne_np', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17123\n"
     ]
    }
   ],
   "source": [
    "print(len(ne_np_df.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [line.rstrip('\\n') for line in open('stop.txt')]\n",
    "values = {}\n",
    "for item in ne_np_df.values.tolist():\n",
    "    ne = clean(item[0])\n",
    "#     ne = ''\n",
    "#     try:\n",
    "#         ne = clean(item[0])\n",
    "#         print(ne)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "    if ne != '' and len(ne) > 2 and ne.lower() not in stop:\n",
    "            if ne in values:\n",
    "                values[ne] += item[1]\n",
    "            else:\n",
    "                values[ne] = item[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16987\n"
     ]
    }
   ],
   "source": [
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values = []\n",
    "for key, item in values.items():\n",
    "    final_values.append([key, item])\n",
    "#final_frame.to_csv('ne_np_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ne_np  count\n",
      "143      people   1584\n",
      "85        power   1350\n",
      "1339      water   1110\n",
      "1336       city   1037\n",
      "405        food    928\n",
      "...         ...    ...\n",
      "5590      smoke     50\n",
      "12821   grandpa     50\n",
      "4201   drinking     50\n",
      "2836      north     50\n",
      "3344       pics     50\n",
      "\n",
      "[547 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "final_frame = pd.DataFrame(final_values, columns = ['ne_np' , 'count'])\n",
    "final_frame = final_frame.loc[~final_frame['ne_np'].str.isnumeric()]\n",
    "filter_frame = final_frame.loc[final_frame['count'] >= 50]\n",
    "filter_frame = filter_frame.sort_values(by='count', ascending = False)\n",
    "print(filter_frame)\n",
    "filter_frame.to_csv('new_YInt_NE_NP.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ne_np  count\n",
      "143                 people   1584\n",
      "85                   power   1350\n",
      "1339                 water   1110\n",
      "1336                  city   1037\n",
      "405                   food    928\n",
      "...                    ...    ...\n",
      "8590           objectively      1\n",
      "8591                 magic      1\n",
      "8595   doriscurioushoggard      1\n",
      "8596                spothe      1\n",
      "16986               morals      1\n",
      "\n",
      "[16987 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "final_frame = final_frame.sort_values(by='count', ascending = False)\n",
    "print(final_frame)\n",
    "final_frame.to_csv('new_YInt_NE_NP_unfiltered.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
