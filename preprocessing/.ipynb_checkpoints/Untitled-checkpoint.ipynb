{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "englishStemmer=SnowballStemmer(\"english\")\n",
    "old1 = pd.read_csv(\"new_YInt_deleted_adv_accounts.csv\")\n",
    "earthquakeList = [englishStemmer.stem(string) for string in ['temblor', 'wobbl', 'quiver', 'trumbl', 'tremor', 'quak', 'seismic', 'shake', 'epicent', 'earthquak', 'shook']]\n",
    "sewer_and_water= [englishStemmer.stem(string) for string in [\"discharged\", \"discharge\", \"drain\", \"drainage\", \"flood\", \"hygiene\", \"irrigation\", \"pipes\", \"pump\", \"river\", \"sanitary\", \"sewage\", \"sewer\", \"stream\", \"underground\", \"wash\", \"waste\", \"water\"]]\n",
    "power_energy= [englishStemmer.stem(string) for string in [\"valve\", \"heat\", \"gas\", \"power\", \"electric\", \"candle\", \"flashlight\", \"generator\", \"black out\", \"blackout\", \"dark\", \"radiation\", \"radio rays\", \"energy\", \"nuclear\", \"fuel\", \"battery\", \"radiant\"]]\n",
    "roads_and_bridges= [englishStemmer.stem(string) for string in [\"airport\", \"avenue\", \"bridge\", \"bus\", \"congestion\", \"drive\", \"flight\", \"jam\", \"logistic\", \"metro\", \"mta\", \"road\", \"street\", \"subway\", \"traffic\", \"train\", \"transit\", \"transportation\", \"highway\", \"route\", \"lane\"]]\n",
    "medical= [englishStemmer.stem(string) for string in [\"medical\", \"red cross\", \"food\", \"emergency\", \"urgent\", \"evacuate\", \"evacuating\", \"evacuation\", \"protection\", \"ambulance\", \"escape\", \"first aid\", \"rescue\", \"rescuing\", \"dead\", \"death\", \"kill\", \"help\", \"help out\", \"help with\", \"volunteer\", \"volunteering\", \"explosion\", \"exploding\", \"explode\", \"victim\", \"fatalities\"]]\n",
    "buildings=[englishStemmer.stem(string) for string in [\"collapse\", \"housing\", \"house\"]]\n",
    "old1['Earthquake'] = \"\"\n",
    "old1['sewer_and_water'] = \"\"\n",
    "old1['power_energy'] = \"\"\n",
    "old1['roads_and_bridges'] = \"\"\n",
    "old1['medical'] = \"\"\n",
    "old1['buildings'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in old1.iterrows():\n",
    "    old1.loc[i,['Earthquake',\"sewer_and_water\",\"power_energy\",\"roads_and_bridges\",\"medical\",\"buildings\"]] = 0\n",
    "    if not pd.isnull(old1.loc[i,'message']):\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'Earthquake'] += old1.loc[i,'message'].count(word)\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'sewer_and_water'] += old1.loc[i,'message'].count(word)\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'power_energy'] += old1.loc[i,'message'].count(word)\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'roads_and_bridges'] += old1.loc[i,'message'].count(word)\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'medical'] += old1.loc[i,'message'].count(word)\n",
    "        for word in earthquakeList:\n",
    "            old1.loc[i,'buildings'] += old1.loc[i,'message'].count(word)\n",
    "old1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old1[\"new_time\"]=pd.to_datetime(old1[\"time\"]).dt.strftime('%Y-%m-%d %H')\n",
    "data=old1.groupby(\"new_time\").apply(lambda x:x[\"Earthquake\"].sum()).reset_index(name=\"Earthquake\")\n",
    "data=data.merge(old1.groupby(\"new_time\").apply(lambda x:x[\"sewer_and_water\"].sum()).reset_index(name=\"sewer_and_water\"),on=\"new_time\",how=\"left\")\n",
    "data=data.merge(old1.groupby(\"new_time\").apply(lambda x:x[\"power_energy\"].sum()).reset_index(name=\"power_energy\"),on=\"new_time\",how=\"left\")\n",
    "data=data.merge(old1.groupby(\"new_time\").apply(lambda x:x[\"roads_and_bridges\"].sum()).reset_index(name=\"roads_and_bridges\"),on=\"new_time\",how=\"left\")\n",
    "data=data.merge(old1.groupby(\"new_time\").apply(lambda x:x[\"medical\"].sum()).reset_index(name=\"medical\"),on=\"new_time\",how=\"left\")\n",
    "data=data.merge(old1.groupby(\"new_time\").apply(lambda x:x[\"buildings\"].sum()).reset_index(name=\"buildings\"),on=\"new_time\",how=\"left\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"area_wide.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
